FROM daocloud.io/ubuntu:trusty
MAINTAINER Vincent Nam <vince797@aliyun.com>
RUN apt-get update && \
    apt-get install -y python \
                       python-dev \
                       python-pip && \
    rm -rf /var/lib/apt/lists/*
RUN mkdir -p /app
WORKDIR /app
CMD ["bash"]


install Docker quicker ;
make sure the container can runs ; 
install the splunk on linux ? 

Clean and maintain you Work PC 

上载：【本地无法使用】
	桌面拖动；
	选择文件，日，那不是
	
Search not executed: The minimum free disk space (5000MB) reached for /opt/splunk/var/run/splunk/dispatch. user=admin.


监视： 一头雾水 ， 添加的日志 刷不出来；

请参阅《更新 Splunk
Enterprise 实例》手册中的“配置部署客户端”

转发器必须成功连接到部署服务器。
转发器配置 为 客户端 配置，部署服务器可管理 转发器 的配置； 

开源的 grafana
为zabbix 做一个 漂亮的图；
特点：
	1 主机 和 监控对象筛选；
	2 为每个目标限定范围； 
	3 支持 模板 仪表盘；（为特定 集群，服务器组，应用程序的迅速改变 显示 数据；）
	4 支持注释：（在图形 里 显示 zabbix事件； ）
	5 显示确认的问题；

--------
监控点； 

找齐伟的那个问题 ； 取mango的延时； 100% 的时候 不准确， 40 %的时候 ，趋势相对平缓； 具体得查查脚本了； 
找Robo的那个问题；  已经得到 数据； 不知道如何看，CM - kafka agent-kafkaserver - pump - Bridge ；

grafana ； 监控业务逻辑 ；       --- 1，自动刷新； 2 如何查看具体项目？ 3 如何自定义模板； 
																	   4，熟悉监控系统 ，从什么地方看起呢-- 要监控的页面是什么？ 问问唐唐 ； 
zabbix ；监控机器性能，服务进程，

--------

### Receiver doesn't accept new connections on it's receiving port ;   
However, sometimes (on Windows machines only) the indexer is unable to reopen the port once its queue is unblocked. To remediate, you must restart(重新启动) the indexer.

you can set the receiver's stopAcceptorAfterQBlock attribute in inputs.conf to a higher value.
so that it does not close the port as quickly. 
This attribute(归属) determines the amount(数量) of time the indexer waits before closing the port. The default is 300 seconds

#### Confusing(混乱) the receiver's receiver and management ports "
####If you setting up a forwarder, you specify(指定) the receiver's hostname/IP_address and port. if you specify a wrong IP or port ;
splunkd.log:03-01-2010 13:35:28.653 ERROR TcpInputFd - SSL Error = error:140760FC:SSL routines:SSL23_GET_CLIENT_HELLO:unknown protocol
splunkd.log:03-01-2010 13:35:28.653 ERROR TcpInputFd - ACCEPT_RESULT=-1 VERIFY_RESULT=0

### Closed receiver socket ；关套接字，这跟一里说的port有什么区别呢？　我勒个日；　都是队列满了造成的；
If a receiving indexer queues become full, it closes the receiver socket(插座) to prevent additional(附加的) forwarders from connecting to it.
The receiver socket reopens(再开) automatically(自动地) when the queue gets unclogged.
### 日志记录 
The following warning message will appear in splunkd.log if the socket gets blocked:
Stopping all listening ports. Queues blocked for more than N seconds. 
This message will appear when the socket(插座) reopens(再开):
Started listening on tcp ports. Queues unblocked. 
### ;


初步看只要我配 了 就可以 通过； 





well 
	
shengjun 给他们建目录；和 权限；  
	
安斌可能需要我配置权限； 加sudo ：问题１：密码怎么办  ；重建sudo ，问strong ；

10.66.66.33  AZ-SPLUNK-INDEX01

Debian DEB install
To install the Splunk DEB package:

dpkg -i splunk_package_name.deb
Note: You can install the Splunk DEB package only in the default location, /opt/splunk.

----------

用户名	全名	电子邮件地址	时区	默认应用	重新启动后台任务
admin	Administrator	changeme@example.com	None	launcher	1


/opt/php/etc/php-fpm.conf


10.8.8.230  

--- Splunk 
连接性； 
indexer 上 可以取到 forwarder上的data ； 


#######For backup； 
http://docs.splunk.com/Documentation/Splunk/6.3.1/Admin/Backupconfigurations
http://docs.splunk.com/Documentation/Splunk/6.3.1/Indexer/Backupindexeddata


齐伟；
display rule ；
延迟

bridge -- insert QPS ； 

------------------------
mactrounk   ； 流量和广告位 ，由百度，新浪这些 发给我们 （10000个qps，即10000个广告位， 允许你的反应时间 100ms）

已下的所有流程 ，控制在 60ms ；

banking  -- 查看广告主 是否有钱，有则投放 广告；  ？ 如何知道广告主是否有钱呢？ 
robots --   查看 广告位 价格是否合理， 合理 则出价； 
frequency -- ； 比如已经给这个 人投放了 2个广告，则避免 再给这个人投放第三次；
cookie-mapping -- ； 查看这个人是不是我们的用户；
	新用户？ -- 写入kafka ；  bridge 会来取 这个数据进行 再处理； 
	老用户？ -- 则排除；后 记录到 【？？？】
render -- ；广告渲染； 投放；  何时？我们就投放 平台广告；
Tracking --- 计算 投放 广告的总量，计算用户点击 的 广告量；
【？？？】 -- ；  cookie 本身有时间限制；我们记录后， 如果过了期，如果再遇到，在其他地方再匹配我们的用户；？？？   
bridge ；  接受kafka 数据；  拿着这些 新 cookie ； 来观察 用户 在哪些平台 浏览过我们 的数据；
logcollect； 所有服务的 日志，放入 hadoop计算，看看我们的投放效果； 

-----------------------
找不到人 ？ 删日志吗？ 




Hi ，Robo ，


已知的流程： 
	cookieMapping 匹配用户； 检测到新的用户，将新cookie记录 写入kafka ； 
	bridge 将数据从 kafaka取出 进行再处理 ；

需要考虑的问题：
 我们担心 cookieMapping的输出，和bridge的输入,中间可能会有丢失请求队列的情况；
 可不可以开发程序，将一个时间段，cookieMapping 中查到的新cookie的记录量 ，和bridge从kafka中取出的量 ，做一个趋势图做一个对比？ 

相同时间段；
CookieMapping 生成的 总量；  趋势图 ？   
VS
bridge 从kafka中接受 到的 数据量； 趋势图？


熟悉 监控 granfna ； 
	我们需要注意哪些监控 ，
		哪几类？ 
		登录方法；
		编辑方法；
	如何编辑这些监控；
	
	
	
我看这个目录下只有三天内的日志； 
$ ssh 10.66.66.91 "ls -lSh /data/tracking/statistic" |more
total 13G
-rw-r--r-- 1 zampuser root   86M Dec 22 10:20 track-p-201512221020.log
-rw-r--r-- 1 zampuser root   81M Dec 21 09:50 track-p-201512210950.log
-rw-r--r-- 1 zampuser root   74M Dec 23 09:40 track-p-201512230940.log
-rw-r--r-- 1 zampuser root   73M Dec 23 09:30 track-p-201512230930.log
-rw-r--r-- 1 zampuser root   73M Dec 23 09:20 track-p-201512230920.log

$ ssh 10.66.66.90 "ls -lSh /data/tracking/statistic" |more
total 13G
-rw-r--r-- 1 zampuser root   86M Dec 22 10:20 track-p-201512221020.log
-rw-r--r-- 1 zampuser root   81M Dec 21 09:50 track-p-201512210950.log
-rw-r--r-- 1 zampuser root   74M Dec 23 09:40 track-p-201512230940.log
-rw-r--r-- 1 zampuser root   74M Dec 23 09:30 track-p-201512230930.log
-rw-r--r-- 1 zampuser root   73M Dec 23 09:20 track-p-201512230920.log

---------Schema 1 

-- 因为有 500M/day 的限制，每天抽几个日志 一个新的日志目录，比如/data/tmpStatistic，     
-- 直接monit这个目录  ； 
-- 控制每天的copy的量，ls更新时间最新的5个日志；排除最新的日志， 计算大小， 如果小于500M 则导入 ；  


-- 1 装Splunk forwarder包  
-- 2 建立新目录 ；定期转移日志；  ---- 这个目录会一天天增大 -- 定期删除 -- 删除后，splunk岂不是读不到了，【确定的】 导入一个月；500*30 = 15000M = 15G 呢

-- 3 控制这个目录的大小； 
-- 4 监控的就是缺失的数据， 比如我们每天监控的都是 固定几个时间段的日志； 【初期就只能这样了】

---------Schema 2
-- 就要一个 连续 时间段的 日志； 不太现实；只有的三天的日志；
 
-- 不支持正则？ 命令行添加， 循环吧 ；
-- 

--- 监视一下我们的Server 根；
azureuser@AZ-Splunk:~$ df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda1        29G  3.5G   25G  13% /
udev            6.9G   12K  6.9G   1% /dev
tmpfs           1.4G  276K  1.4G   1% /run
none            5.0M     0  5.0M   0% /run/lock
none            6.9G   12K  6.9G   1% /run/shm
none             64K     0   64K   0% /etc/network/interfaces.dynamic.d
/dev/sdb1       596G   70M  566G   1% /mnt

-- 离散的日志， 循环导入 ，达到阀值； 第一二次导入，计数1，2；TM再导入就超过了，
-- 只能把 离散的日志 写入一个大日志里，一次导入； ok；
1 超过 ；


-rw-r--r-- 1 zampuser root 42288536 Dec 21 00:10 /data/tracking/statistic/track-p-201512210010.log
-rw-r--r-- 1 zampuser root   457481 Dec 21 00:10 /data/tracking/statistic/track-s-201512210010.log
-rw-r--r-- 1 zampuser root     1262 Dec 21 00:09 /data/tracking/statistic/track-c-201512210010.log

ls -t /data/tracking/statistic/track-p

more 然后echo 进去的话，应该不用排除第一行 ；

ls -lrt /data/tracking/statistic/track-c-* |awk -F " " '{print $NF}' |while read lines;do cat $lines >> /data/tracking/statistic/temp/track-c-21-22-23-24.log;echo "$lines has done";done 
ls -lrt /data/tracking/statistic/track-s-* |awk -F " " '{print $NF}' |while read lines;do cat $lines >> /data/tracking/statistic/temp/track-s-21-22-23-24.log;echo "$lines has done";done 
ls -lrt /data/tracking/statistic/track-p-* |awk -F " " '{print $NF}' |while read lines;do cat $lines >> /data/tracking/statistic/temp/track-p-21-22-23-24.log;echo "$lines has done";done 


watch -n 3  -d df -h ## 3s 观察 磁盘 数值 变化； 

/dev/mapper/datavg-ptracking  295G   13G  267G   5% /data/tracking/statistic            

那如果你往 /data/tmp 目录下写日志，可不是写在这个目录下了，而是 / 下了，换句话说，把根写满了you 就SB了； {SOX} 级别的吧 ； 

小心没有坏处； 

####
*/10 * * * * bash /usr/local/zamplus-ptracking-server/bin/log_rotate.sh 
# log clean 
5 0 * * * bash /usr/local/zamplus-ptracking-server/bin/log_clean.sh

find ${_log_statistic_dir}/ -type f -mtime +2 -name "*.log" -exec rm -rf {} \;

还好，丫只是 把 log 关键字 给干掉； 重命名，让丫不带log就好；

### 

10.66.66.37 
vince@AZ-TRK02:~$ df -h
Filesystem                    Size  Used Avail Use% Mounted on
/dev/sda1                      29G   13G   15G  47% /
udev                          3.4G   12K  3.4G   1% /dev
tmpfs                         698M  292K  697M   1% /run
none                          5.0M     0  5.0M   0% /run/lock
none                          3.5G   12K  3.5G   1% /run/shm
none                           64K     0   64K   0% /etc/network/interfaces.dynamic.d
/dev/sdb1                     281G   63M  267G   1% /mnt
/dev/mapper/datavg-ptracking  295G   24G  256G   9% /data/tracking/statistic

#######

indexer  如果安装了forwarder ；破坏了原包？ 卸载掉，而且安装目录也不同， 会不会影响用户呢！ 这个比较恶心，要是在我自己的环境里还好； -- 貌似没有影响；服务的运行期间； 


老板要全部导入 13G 
	
------
如何让领导 快速 熟悉这个过程？ 重点，一目了然；方便快速指定方案； 

source=/var/log/dpkg.log


salt 太慢了；


 ansible azuredmp -m shell -a '/etc/init.d/salt-minion restart'
 
 

server {
    listen 8090;
    server_name 10.66.66.26;
    root        /usr/local/temp/;
    autoindex on;
    autoindex_exact_size off;
    autoindex_localtime on;

}

[vince@CPIC-DMP11 conf.d]$ ls /usr/local/temp/
nginx+php1.2-full.tar.gz



Well
一 首先要下载包；
  wget http://azure-cpic.chinacloudapp.cn:8080/nginx+php1.2-full.tar.gz
   
	或者访问 下面的web都可以下载； 
	http://azure-cpic.chinacloudapp.cn:8080 

二.可能碰到的问题 ；
1 开始安装 ，
[azureuser@CPIC-DMP22 nginx+php1.2-full]$ sudo script
centos.sh  freetype-2.4.12.tar.gz  init.d.php-fpm5.6      libmcrypt-2.5.8.tar.gz  mcrypt-2.6.8.tar.gz   nginx-1.6.2.tar.gz  pcre-8.12.tar.gz  typescript
conf       init.d.nginx            init.d.php-fpm-centos  libxml2-2.7.8.tar.gz    mhash-0.9.9.9.tar.gz  nginx-centos-conf   php-5.6.6.tar.gz  ubuntu.sh
[root@CPIC-DMP22 nginx+php1.2-full]# sh centos.sh 

2 安装过程非常慢，可以watch -n 3 查看nginx+php1.2-full 目录下文件的更新状况；

3。终于安装完成；
=========================================================================
===========================add nginx and php-fpm on startup completed====================

4 执行下面的操作；
# sudo cp /opt/nginx/etc/nginx/nginx.conf  /opt/nginx/etc/nginx/conf/nginx.conf
# sudo mkdir /opt/run/

$ sudo mv /opt/php /opt/php-fpm
# 编辑/etc/init.d/php-fpm ，改成这一项 php_fpm_BIN=/opt/php-fpm/sbin/php-fpm
# sudo mkdir /opt/log/php-fpm/
$ sudo mkdir /opt/run/php-fpm/

5 脚本/etc/init.d/php-fpm ， /etc/init.d/nginx 就都应该可以用了；  如果还有问题，可以看看具体报什么错；
# /etc/init.d/nginx configtest
# /etc/init.d/php-fpm start  












[vince@CPIC-DMP11 conf.d]$ sudo more /opt/nginx/logs/nginx.pid 
[vince@CPIC-DMP11 conf.d]$ sudo more /opt/run/nginx.pid 
7676

	reload)

		echo -n "Reload service $NAME... "

		if netstat -tnpl | grep -q nginx; then
			/usr/bin/nginx -s reload
			echo " done"
		else
			echo "$NAME is not running, can't reload."
			exit 1
		fi

---------------
远程 连接 机房；  无法提供yum ， 对应包无法安装 
--提取出yum 源的对应的rpm； 把这些rpm 都弄到 源码包里；  
--让我今天搞定 ； 
--robo下午 要过去 ；  
先和周总 说这个问题； 




cp /etc/yum.conf /etc/yum.conf.nginxphp > /dev/null 2>&1;echo "========================================================================="
sed -i 's:exclude=.*:exclude=:g' /etc/yum.conf > /dev/null 2>&1


      mv -f /etc/yum.conf.nginxphp /etc/yum.conf > /dev/null 2>&1
      
      
      
$ yum deplist gcc make




patch make cmake gcc gcc-c++ gcc-g77 flex bison file libtool libtool-libs autoconf kernel-devel libjpeg libjpeg-devel libpng libpng-devel libpng10 libpng10-devel gd gd-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glib2 glib2-devel bzip2 bzip2-devel libevent libevent-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5 krb5-devel libidn libidn-devel openssl openssl-devel vim-minimal nano fonts-chinese gettext gettext-devel ncurses-devel gmp-devel pspell-devel unzip libcap diffutils

10.66.66.26

## x86
$ more rpm/depend1  |grep package  |grep -v i686 |wc -l
59

# 精确，不重复； 这里不重复的话； 上面的长输出 ，精确到 x86的包； 
$  more rpm/depend1  |grep package  |grep -v i686 |awk '{print $2}' |uniq > rpm/depend2


即使 依赖性 也有版本问题 --- 过滤出来以后 ，awk 再 排除多余的； 
  dependency: libc.so.6(GLIBC_2.4)(64bit)
   provider: glibc.x86_64 2.12-1.166.el6
   provider: glibc.x86_64 2.12-1.166.el6_7.1
   provider: glibc.x86_64 2.12-1.166.el6_7.3

centOS上 搜出来的包无法对比 rhel 的，名字不一样 ； 
[vince@CPIC-DMP11 nginx+php1.2.3-full]$ more rpm/depend3 |egrep "(package|provider)" |grep -v i686 |awk '{print $2}' |uniq |sort |uniq |wc -l
117

--简化名字 ； 
$ more rpm/depend3 |egrep "(package|provider)" |grep -v i686 |awk '{print $2}' |uniq |sort |uniq |awk -F ".x86" '{print $1}' > rpm/depend4

-- 列出来 ，再过滤norch ；
$ more rpm/depend4  |awk -F "." '{print $1}' > rpm/depend5


### 回到RHEL  

yum deplist gcc make  这个包用不上； 

脚本执行完了， php却无法安装； 肯定有缺失文件 了

用的一个关键字就匹配了太多信息了； 
python-twisted-lore-8.2.0-3.2.el6.x86_64.rpm
python-twisted-mail-8.2.0-3.2.el6.x86_64.rpm
python-twisted-names-8.2.0-3.2.el6.x86_64.rpm
python-twisted-news-8.2.0-3.2.el6.x86_64.rpm
python-twisted-runner-8.2.0-3.2.el6.x86_64.rpm
python-twisted-web-8.2.0-3.2.el6.x86_64.rpm
python-twisted-words-8.2.0-3.2.el6.x86_64.rpm
python-urlgrabber-3.9.1-8.el6.noarch.rpm



这个无法排除了； rpm ，不注册还查不了依赖性了我次奥；；

让rhel 注册 centOS 的yum ，还有可能解决，次奥； 




more rpm/depend5  

  353  more rpm/depend5 |egrep -v "(devel|libs)" > rpm/depend_no_devel_libs   全的 ；什么字符都有 ；-- grep的话 -- 一堆字段-- 弄出来只装devel和libs？--不成立 -- got stuck ；
  
  354  more rpm/depend5 |egrep "(devel|libs)" > rpm/depend_devel_libs  只有devel 的包，和 libs 的包； 


# df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                       50G  1.7G   46G   4% /
tmpfs                 1.9G     0  1.9G   0% /dev/shm
/dev/xvda1            485M   32M  428M   7% /boot
/dev/mapper/VolGroup-lv_home
                      144G  188M  136G   1% /home
/dev/xvdd1            3.5G  3.5G     0 100% /mnt/cdrom

  但是我如果安装   
  
# 还是漏了两个关键性的包；导致无法 编译； 
  glibc-headers-2.12-1.107.el6.x86_64.rpm
  kernel-headers-2.6.32-358.el6.x86_64.rpm
  
-------
57.56  ；


172.22.56.21


测试通过splunk添加转发器日志功能；
指定splunk日志导入计划，尝试合并ZAMP tracking data日志；
尝试解决nginx-php-fpm源码包的依赖性关系问题；
上线goodman  OPTSERVICE-4422 
上线robots；OPTSERVICE-4431
上线megatron-sserver OPTSERVICE-4436


Baidu
172.22.56.21
172.22.57.26
172.22.57.27
172.22.57.28
172.22.57.73
172.22.48.11
172.22.57.74
172.22.57.75

Tanx
172.22.56.1
172.22.57.22
172.22.57.23
172.22.57.40
172.22.57.48
172.22.48.9
172.22.57.55
172.22.57.71
172.22.57.62
172.22.57.61

Sina
172.22.57.24
172.22.57.25
172.22.57.58
172.22.57.71
172.22.57.56


