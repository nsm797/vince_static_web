FROM daocloud.io/ubuntu:trusty
MAINTAINER Vincent Nam <vince797@aliyun.com>
RUN apt-get update && \
    apt-get install -y python \
                       python-dev \
                       python-pip && \
    rm -rf /var/lib/apt/lists/*
RUN mkdir -p /app
WORKDIR /app
CMD ["bash"]


install Docker quicker ;
make sure the container can runs ; 
install the splunk on linux   

Clean and maintain you Work PC 

上载：【本地无法使用】
   桌面拖动；
   选择文件，日，那不是
   
Search not executed: The minimum free disk space (5000MB) reached for /opt/splunk/var/run/splunk/dispatch. user=admin.


监视： 一头雾水 ， 添加的日志 刷不出来；

请参阅《更新 Splunk
Enterprise 实例》手册中的“配置部署客户端”

转发器必须成功连接到部署服务器。
转发器配置 为 客户端 配置，部署服务器可管理 转发器 的配置； 

开源的 grafana
为zabbix 做一个 漂亮的图；
特点：
   1 主机 和 监控对象筛选；
   2 为每个目标限定范围； 
   3 支持 模板 仪表盘；（为特定 集群，服务器组，应用程序的迅速改变 显示 数据；）
   4 支持注释：（在图形 里 显示 zabbix事件； ）
   5 显示确认的问题；

--------
监控点； 

找齐伟的那个问题 ； 取mango的延时； 100% 的时候 不准确， 40 %的时候 ，趋势相对平缓； 具体得查查脚本了； 
找Robo的那个问题；  已经得到 数据； 不知道如何看，CM - kafka agent-kafkaserver - pump - Bridge ；

grafana ； 监控业务逻辑 ；       --- 1，自动刷新； 2 如何查看具体项目？ 3 如何自定义模板； 
                                                      4，熟悉监控系统 ，从什么地方看起呢-- 要监控的页面是什么？ 问问唐唐 ； 
zabbix ；监控机器性能，服务进程，

--------

### Receiver doesn't accept new connections on it's receiving port ;   
However, sometimes (on Windows machines only) the indexer is unable to reopen the port once its queue is unblocked. To remediate, you must restart(重新启动) the indexer.

you can set the receiver's stopAcceptorAfterQBlock attribute in inputs.conf to a higher value.
so that it does not close the port as quickly. 
This attribute(归属) determines the amount(数量) of time the indexer waits before closing the port. The default is 300 seconds

#### Confusing(混乱) the receiver's receiver and management ports "
####If you setting up a forwarder, you specify(指定) the receiver's hostname/IP_address and port. if you specify a wrong IP or port ;
splunkd.log:03-01-2010 13:35:28.653 ERROR TcpInputFd - SSL Error = error:140760FC:SSL routines:SSL23_GET_CLIENT_HELLO:unknown protocol
splunkd.log:03-01-2010 13:35:28.653 ERROR TcpInputFd - ACCEPT_RESULT=-1 VERIFY_RESULT=0

### Closed receiver socket ；关套接字，这跟一里说的port有什么区别呢？　我勒个日；　都是队列满了造成的；
If a receiving indexer queues become full, it closes the receiver socket(插座) to prevent additional(附加的) forwarders from connecting to it.
The receiver socket reopens(再开) automatically(自动地) when the queue gets unclogged.
### 日志记录 
The following warning message will appear in splunkd.log if the socket gets blocked:
Stopping all listening ports. Queues blocked for more than N seconds. 
This message will appear when the socket(插座) reopens(再开):
Started listening on tcp ports. Queues unblocked. 
### ;


初步看只要我配 了 就可以 通过； 





well 
   

用户名   全名   电子邮件地址   时区   默认应用   重新启动后台任务
admin   Administrator   changeme@example.com   None   launcher   1


/opt/php/etc/php-fpm.conf


10.8.8.230  

--- Splunk 
连接性； 
indexer 上 可以取到 forwarder上的data ； 


#######For backup； 
http://docs.splunk.com/Documentation/Splunk/6.3.1/Admin/Backupconfigurations
http://docs.splunk.com/Documentation/Splunk/6.3.1/Indexer/Backupindexeddata


------------------------
mactrounk   ； 流量和广告位 ，由百度，新浪这些 发给我们 （10000个qps，即10000个广告位， 允许你的反应时间 100ms）

已下的所有流程 ，控制在 60ms ；

banking  -- 查看广告主 是否有钱，有则投放 广告；  ？ 如何知道广告主是否有钱呢？ 
robots --   查看 广告位 价格是否合理， 合理 则出价； 
frequency -- ； 比如已经给这个 人投放了 2个广告，则避免 再给这个人投放第三次；
cookie-mapping -- ； 查看这个人是不是我们的用户；
   新用户？ -- 写入kafka ；  bridge 会来取 这个数据进行 再处理； 
   老用户？ -- 则排除；后 记录到 【？？？】
render -- ；广告渲染； 投放；  何时？我们就投放 平台广告；
Tracking --- 计算 投放 广告的总量，计算用户点击 的 广告量；
【？？？】 -- ；  cookie 本身有时间限制；我们记录后， 如果过了期，如果再遇到，在其他地方再匹配我们的用户；？？？   
bridge ；  接受kafka 数据；  拿着这些 新 cookie ； 来观察 用户 在哪些平台 浏览过我们 的数据；
logcollect； 所有服务的 日志，放入 hadoop计算，看看我们的投放效果； 

-----------------------
找不到人 ？ 删日志吗？ 




Hi ，Robo ，


已知的流程： 
   cookieMapping 匹配用户； 检测到新的用户，将新cookie记录 写入kafka ； 
   bridge 将数据从 kafaka取出 进行再处理 ；

需要考虑的问题：
 我们担心 cookieMapping的输出，和bridge的输入,中间可能会有丢失请求队列的情况；
 可不可以开发程序，将一个时间段，cookieMapping 中查到的新cookie的记录量 ，和bridge从kafka中取出的量 ，做一个趋势图做一个对比？ 

相同时间段；
CookieMapping 生成的 总量；  趋势图 ？   
VS
bridge 从kafka中接受 到的 数据量； 趋势图？


熟悉 监控 granfna ； 
   我们需要注意哪些监控 ，
      哪几类？ 
      登录方法；
      编辑方法；
   如何编辑这些监控；
   
   
   
我看这个目录下只有三天内的日志； 
$ ssh 10.66.66.91 "ls -lSh /data/tracking/statistic" |more
total 13G
-rw-r--r-- 1 zampuser root   86M Dec 22 10:20 track-p-201512221020.log
-rw-r--r-- 1 zampuser root   81M Dec 21 09:50 track-p-201512210950.log
-rw-r--r-- 1 zampuser root   74M Dec 23 09:40 track-p-201512230940.log
-rw-r--r-- 1 zampuser root   73M Dec 23 09:30 track-p-201512230930.log
-rw-r--r-- 1 zampuser root   73M Dec 23 09:20 track-p-201512230920.log

$ ssh 10.66.66.90 "ls -lSh /data/tracking/statistic" |more
total 13G
-rw-r--r-- 1 zampuser root   86M Dec 22 10:20 track-p-201512221020.log
-rw-r--r-- 1 zampuser root   81M Dec 21 09:50 track-p-201512210950.log
-rw-r--r-- 1 zampuser root   74M Dec 23 09:40 track-p-201512230940.log
-rw-r--r-- 1 zampuser root   74M Dec 23 09:30 track-p-201512230930.log
-rw-r--r-- 1 zampuser root   73M Dec 23 09:20 track-p-201512230920.log

---------Schema 1 

-- 因为有 500M/day 的限制，每天抽几个日志 一个新的日志目录，比如/data/tmpStatistic，     
-- 直接monit这个目录  ； 
-- 控制每天的copy的量，ls更新时间最新的5个日志；排除最新的日志， 计算大小， 如果小于500M 则导入 ；  


-- 1 装Splunk forwarder包  
-- 2 建立新目录 ；定期转移日志；  ---- 这个目录会一天天增大 -- 定期删除 -- 删除后，splunk岂不是读不到了，【确定的】 导入一个月；500*30 = 15000M = 15G 呢

-- 3 控制这个目录的大小； 
-- 4 监控的就是缺失的数据， 比如我们每天监控的都是 固定几个时间段的日志； 【初期就只能这样了】

---------Schema 2
-- 就要一个 连续 时间段的 日志； 不太现实；只有的三天的日志；
 
-- 不支持正则？ 命令行添加， 循环吧 ；
-- 

--- 监视一下我们的Server 根；
azureuser@AZ-Splunk:~$ df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda1        29G  3.5G   25G  13% /
udev            6.9G   12K  6.9G   1% /dev
tmpfs           1.4G  276K  1.4G   1% /run
none            5.0M     0  5.0M   0% /run/lock
none            6.9G   12K  6.9G   1% /run/shm
none             64K     0   64K   0% /etc/network/interfaces.dynamic.d
/dev/sdb1       596G   70M  566G   1% /mnt

-- 离散的日志， 循环导入 ，达到阀值； 第一二次导入，计数1，2；TM再导入就超过了，
-- 只能把 离散的日志 写入一个大日志里，一次导入； ok；
1 超过 ；


-rw-r--r-- 1 zampuser root 42288536 Dec 21 00:10 /data/tracking/statistic/track-p-201512210010.log
-rw-r--r-- 1 zampuser root   457481 Dec 21 00:10 /data/tracking/statistic/track-s-201512210010.log
-rw-r--r-- 1 zampuser root     1262 Dec 21 00:09 /data/tracking/statistic/track-c-201512210010.log

ls -t /data/tracking/statistic/track-p

more 然后echo 进去的话，应该不用排除第一行 ；

ls -lrt /data/tracking/statistic/track-c-* |awk -F " " '{print $NF}' |while read lines;do cat $lines >> /data/tracking/statistic/temp/track-c-21-22-23-24.log;echo "$lines has done";done 
ls -lrt /data/tracking/statistic/track-s-* |awk -F " " '{print $NF}' |while read lines;do cat $lines >> /data/tracking/statistic/temp/track-s-21-22-23-24.log;echo "$lines has done";done 
ls -lrt /data/tracking/statistic/track-p-* |awk -F " " '{print $NF}' |while read lines;do cat $lines >> /data/tracking/statistic/temp/track-p-21-22-23-24.log;echo "$lines has done";done 


watch -n 3  -d df -h ## 3s 观察 磁盘 数值 变化； 

/dev/mapper/datavg-ptracking  295G   13G  267G   5% /data/tracking/statistic            

那如果你往 /data/tmp 目录下写日志，可不是写在这个目录下了，而是 / 下了，换句话说，把根写满了you 就SB了； {SOX} 级别的吧 ； 

小心没有坏处； 

####
*/10 * * * * bash /usr/local/zamplus-ptracking-server/bin/log_rotate.sh 
# log clean 
5 0 * * * bash /usr/local/zamplus-ptracking-server/bin/log_clean.sh

find ${_log_statistic_dir}/ -type f -mtime +2 -name "*.log" -exec rm -rf {} \;

还好，丫只是 把 log 关键字 给干掉； 重命名，让丫不带log就好；

### 

10.66.66.37 
vince@AZ-TRK02:~$ df -h
Filesystem                    Size  Used Avail Use% Mounted on
/dev/sda1                      29G   13G   15G  47% /
udev                          3.4G   12K  3.4G   1% /dev
tmpfs                         698M  292K  697M   1% /run
none                          5.0M     0  5.0M   0% /run/lock
none                          3.5G   12K  3.5G   1% /run/shm
none                           64K     0   64K   0% /etc/network/interfaces.dynamic.d
/dev/sdb1                     281G   63M  267G   1% /mnt
/dev/mapper/datavg-ptracking  295G   24G  256G   9% /data/tracking/statistic

#######

indexer  如果安装了forwarder ；破坏了原包？ 卸载掉，而且安装目录也不同， 会不会影响用户呢！ 这个比较恶心，要是在我自己的环境里还好； -- 貌似没有影响；服务的运行期间； 


老板要全部导入 13G 
   
------
如何让领导 快速 熟悉这个过程？ 重点，一目了然；方便快速指定方案； 

source=/var/log/dpkg.log


salt 太慢了；


 ansible azuredmp -m shell -a '/etc/init.d/salt-minion restart'
 
 

server {
    listen 8090;
    server_name 10.66.66.26;
    root        /usr/local/temp/;
    autoindex on;
    autoindex_exact_size off;
    autoindex_localtime on;

}

[vince@CPIC-DMP11 conf.d]$ ls /usr/local/temp/
nginx+php1.2-full.tar.gz



Well
一 首先要下载包；
  wget http://azure-cpic.chinacloudapp.cn:8080/nginx+php1.2-full.tar.gz
   
   或者访问 下面的web都可以下载； 
   http://azure-cpic.chinacloudapp.cn:8080 

二.可能碰到的问题 ；
1 开始安装 ，
[azureuser@CPIC-DMP22 nginx+php1.2-full]$ sudo script
centos.sh  freetype-2.4.12.tar.gz  init.d.php-fpm5.6      libmcrypt-2.5.8.tar.gz  mcrypt-2.6.8.tar.gz   nginx-1.6.2.tar.gz  pcre-8.12.tar.gz  typescript
conf       init.d.nginx            init.d.php-fpm-centos  libxml2-2.7.8.tar.gz    mhash-0.9.9.9.tar.gz  nginx-centos-conf   php-5.6.6.tar.gz  ubuntu.sh
[root@CPIC-DMP22 nginx+php1.2-full]# sh centos.sh 

2 安装过程非常慢，可以watch -n 3 查看nginx+php1.2-full 目录下文件的更新状况；

3。终于安装完成；
=========================================================================
===========================add nginx and php-fpm on startup completed====================

4 执行下面的操作；
# sudo cp /opt/nginx/etc/nginx/nginx.conf  /opt/nginx/etc/nginx/conf/nginx.conf
# sudo mkdir /opt/run/

$ sudo mv /opt/php /opt/php-fpm
# 编辑/etc/init.d/php-fpm ，改成这一项 php_fpm_BIN=/opt/php-fpm/sbin/php-fpm
# sudo mkdir /opt/log/php-fpm/
$ sudo mkdir /opt/run/php-fpm/

5 脚本/etc/init.d/php-fpm ， /etc/init.d/nginx 就都应该可以用了；  如果还有问题，可以看看具体报什么错；
# /etc/init.d/nginx configtest
# /etc/init.d/php-fpm start  












[vince@CPIC-DMP11 conf.d]$ sudo more /opt/nginx/logs/nginx.pid 
[vince@CPIC-DMP11 conf.d]$ sudo more /opt/run/nginx.pid 
7676

   reload)

      echo -n "Reload service $NAME... "

      if netstat -tnpl | grep -q nginx; then
         /usr/bin/nginx -s reload
         echo " done"
      else
         echo "$NAME is not running, can't reload."
         exit 1
      fi

---------------
远程 连接 机房；  无法提供yum ， 对应包无法安装 
--提取出yum 源的对应的rpm； 把这些rpm 都弄到 源码包里；  
--让我今天搞定 ； 
--robo下午 要过去 ；  
先和周总 说这个问题； 




cp /etc/yum.conf /etc/yum.conf.nginxphp > /dev/null 2>&1;echo "========================================================================="
sed -i 's:exclude=.*:exclude=:g' /etc/yum.conf > /dev/null 2>&1


      mv -f /etc/yum.conf.nginxphp /etc/yum.conf > /dev/null 2>&1
      
      
      
$ yum deplist gcc make




patch make cmake gcc gcc-c++ gcc-g77 flex bison file libtool libtool-libs autoconf kernel-devel libjpeg libjpeg-devel libpng libpng-devel libpng10 libpng10-devel gd gd-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glib2 glib2-devel bzip2 bzip2-devel libevent libevent-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5 krb5-devel libidn libidn-devel openssl openssl-devel vim-minimal nano fonts-chinese gettext gettext-devel ncurses-devel gmp-devel pspell-devel unzip libcap diffutils

10.66.66.26

## x86
$ more rpm/depend1  |grep package  |grep -v i686 |wc -l
59

# 精确，不重复； 这里不重复的话； 上面的长输出 ，精确到 x86的包； 
$  more rpm/depend1  |grep package  |grep -v i686 |awk '{print $2}' |uniq > rpm/depend2


即使 依赖性 也有版本问题 --- 过滤出来以后 ，awk 再 排除多余的； 
  dependency: libc.so.6(GLIBC_2.4)(64bit)
   provider: glibc.x86_64 2.12-1.166.el6
   provider: glibc.x86_64 2.12-1.166.el6_7.1
   provider: glibc.x86_64 2.12-1.166.el6_7.3

centOS上 搜出来的包无法对比 rhel 的，名字不一样 ； 
[vince@CPIC-DMP11 nginx+php1.2.3-full]$ more rpm/depend3 |egrep "(package|provider)" |grep -v i686 |awk '{print $2}' |uniq |sort |uniq |wc -l
117

--简化名字 ； 
$ more rpm/depend3 |egrep "(package|provider)" |grep -v i686 |awk '{print $2}' |uniq |sort |uniq |awk -F ".x86" '{print $1}' > rpm/depend4

-- 列出来 ，再过滤norch ；
$ more rpm/depend4  |awk -F "." '{print $1}' > rpm/depend5


### 回到RHEL  

yum deplist gcc make  这个包用不上； 

脚本执行完了， php却无法安装； 肯定有缺失文件 了

用的一个关键字就匹配了太多信息了； 
python-twisted-lore-8.2.0-3.2.el6.x86_64.rpm
python-twisted-mail-8.2.0-3.2.el6.x86_64.rpm
python-twisted-names-8.2.0-3.2.el6.x86_64.rpm
python-twisted-news-8.2.0-3.2.el6.x86_64.rpm
python-twisted-runner-8.2.0-3.2.el6.x86_64.rpm
python-twisted-web-8.2.0-3.2.el6.x86_64.rpm
python-twisted-words-8.2.0-3.2.el6.x86_64.rpm
python-urlgrabber-3.9.1-8.el6.noarch.rpm



这个无法排除了； rpm ，不注册还查不了依赖性了我次奥；；

让rhel 注册 centOS 的yum ，还有可能解决，次奥； 




more rpm/depend5  

  353  more rpm/depend5 |egrep -v "(devel|libs)" > rpm/depend_no_devel_libs   全的 ；什么字符都有 ；-- grep的话 -- 一堆字段-- 弄出来只装devel和libs？--不成立 -- got stuck ；
  
  354  more rpm/depend5 |egrep "(devel|libs)" > rpm/depend_devel_libs  只有devel 的包，和 libs 的包； 


# df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup-lv_root
                       50G  1.7G   46G   4% /
tmpfs                 1.9G     0  1.9G   0% /dev/shm
/dev/xvda1            485M   32M  428M   7% /boot
/dev/mapper/VolGroup-lv_home
                      144G  188M  136G   1% /home
/dev/xvdd1            3.5G  3.5G     0 100% /mnt/cdrom

  但是我如果安装   
  
# 还是漏了两个关键性的包；导致无法 编译； 
  glibc-headers-2.12-1.107.el6.x86_64.rpm
  kernel-headers-2.6.32-358.el6.x86_64.rpm
  
-------
57.56  ；


172.22.56.21





vince@TS-W01:/var/log$ 

## 没有加入logrotate
vince@TS-W01:/var/log$ ls -lSh  Mars/ |more
total 36G
-rw-r--r-- 1 www-data root  19G Dec 28 11:04 access.mars.log
-rw-r----- 1 root     root  17G Dec 28 11:04 uwsgi.log

## 文件 特别大
vince@TS-W01:/var/log$ sudo ls -lSh  zampdsp/*  |more
-rwxr-xr-x 1 root     root  83G Sep 27 10:20 zampdsp/zampdsp.uwsgi

## 

玩大架构，大平台；必须心思缜密； 紧急的事固然重要； 重要的事才是关键，否则只是不停的救火而已；

Step 1 先加上我的账户再说； 
10.66.66.38 centos # account # no sudo ；
10.66.66.37        # no account # 


## Todolist ；



19800 
加硬解
/etc/salt/minion
{master: 172.22.40.251
id: FW8PKY1}
master: 172.22.40.251
id: 1084-1595-0058-6840-0592-2688-96


  slave机器：
          sudo apt-get install salt-minion
          编辑/etc/salt/minion文件：
          master: 172.16.43.131（master机器ip）
          id: max3 （机器代号）                                    ###############这个机器代号是随便起吗？　根据什么呢？　
          重启 salt-minion   
  slave机器：
          sudo apt-get install salt-minion
          编辑/etc/salt/minion文件：
          master: 172.16.43.131（master机器ip）
          id: max3 （机器代号）                                    ###############这个机器代号是随便起吗？　根据什么呢？　
          重启 salt-minion   



log_format main '$remote_addr - $remote_user [$time_local] '
                     'fwf[$http_x_forwarded_for] tip[$http_true_client_ip] '
                     '$upstream_addr $upstream_response_time $request_time '
                     '$geoip_country_code '
                     '$http_host $request '
                     '"$status" $body_bytes_sent "$http_referer" '
                     '"$http_accept_language" "$http_user_agent" ';
                     
remote_addr remote_user       time_local         forward  client  upstream_addr             http_host     request                      status
201.158.69.116 - - [03/Jan/2013:21:17:20 -0600] fwf[-] tip[-] 127.0.0.1:9000 0.007 0.007 MX pythontab.com GET /html/test.html HTTP/1.1 "200" 2426 "http://a.com" "es-ES,es;q=0.8" "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.97 Safari/537.11"
187.171.69.177 - - [03/Jan/2013:21:17:20 -0600] fwf[-] tip[-] 127.0.0.1:9000 0.006 0.006 MX pythontab.com GET /html/test2.html HTTP/1.1 "200" 2426 "http://a.com" "es-ES,es;q=0.8" "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.97 Safari/537.11"


-----------------------------
用户名ff，密码：Redhat1!
IP:vpn.jiwei.me
pptp协议的



Hi 在 ubuntu上如何配置salt client ？ 10.66.66.37

我执行了文档上的操作，还是无法远程添加自己的账户 ！

 slave机器：
          sudo apt-get install salt-minion
          编辑/etc/salt/minion文件：
          master: 172.16.43.131（master机器ip）
          id: max3 （机器代号）
          重启 salt-minion
          
          
Hi，你帮我原来添加的那台salt client ；；
10.66.66.38   salt   [vince@CPIC-DMP22 ~]$ sudo ps -ef 
[sudo] password for vince: 
vince is not in the sudoers file.  This incident will be reported.
[vince@CPIC-DMP22 ~]$ 
[vince@CPIC-DMP22 ~]$ 
[vince@CPIC-DMP22 ~]$ id vince
uid=502(vince) gid=502(vince) groups=502(vince),10(wheel)


salt -G "ipv4:10.66.66.37"  cmd.run "w"



10.66.66.38   centOS   no sudo 
vince is not in the sudoers file.  This incident will be reported.

$ id vince
uid=502(vince) gid=502(vince) groups=502(vince),10(wheel)


还有我在一些机器上没有sudo 权限！ 10.66.66.38  ； 
vince is not in the sudoers file.  This incident will be reported.
[vince@CPIC-DMP22 ~]$ id vince
uid=502(vince) gid=502(vince) groups=502(vince),10(wheel)


## 
Add zabbix agent ;

-- open 10050 ;10051 tcp & udp ;
-A INPUT -s 192.168.21.127 -m state --state NEW -m tcp -p tcp --dport 10050:10051 -j ACCEPT
-A INPUT -s 192.168.21.127 -m state --state NEW -m udp -p udp --dport 10050:10051 -j ACCEPT




###########Important;
Add email on my iphone ; 
salt permision issue ; 
Read python book ; liao ? & find the useful modules ; 



## Ubuntu 
# dpkg -l |grep zabbix
ii  zabbix-agent                      1:1.8.11-1                                  network monitoring solution - agent

### include 
/usr
/usr/bin
/usr/bin/zabbix_agent
/usr/bin/zabbix_sender
/usr/share
/usr/share/doc
/usr/share/doc/zabbix-agent
/usr/share/doc/zabbix-agent/copyright
/usr/share/doc/zabbix-agent/README.Debian
/usr/share/doc/zabbix-agent/changelog.Debian.gz
/usr/share/man
/usr/share/man/man1
/usr/share/man/man1/zabbix_sender.1.gz
/usr/share/man/man8
/usr/share/man/man8/zabbix_agentd.8.gz
/usr/share/zabbix-agent
/usr/share/zabbix-agent/zabbix_agentd.conf
/usr/sbin
/usr/sbin/zabbix_agentd
/var
/var/log
/var/log/zabbix-agent
/etc
/etc/init.d
/etc/init.d/zabbix-agent
/etc/logrotate.d
/etc/logrotate.d/zabbix-agent
/etc/zabbix
/etc/zabbix/zabbix_agentd.conf.d

### main conf 
# more /etc/zabbix/zabbix_agentd.conf
PidFile=/var/run/zabbix/zabbix_agentd.pid
LogFile=/var/log/zabbix-agent/zabbix_agentd.log
LogFileSize=0
DebugLevel=1
DisableActive=1
Server=172.22.40.250
StartAgents=5
Timeout=30
Include=/etc/zabbix/zabbix_agentd.conf.d/

## monitor item ;  confined by US ; 
root@TS-OP03:~# cd /etc/zabbix/zabbix_agentd.conf.d/
root@TS-OP03:/etc/zabbix/zabbix_agentd.conf.d# ls
core_file_created.conf  os.basic.conf

root@TS-OP03:/etc/zabbix/zabbix_agentd.conf.d# more core_file_created.conf 
UserParameter=corefile[*],         bash /home/zabbix/agent_bin/check_core_created.sh $1 $2

root@TS-OP03:/etc/zabbix/zabbix_agentd.conf.d# more os.basic.conf 
#agent
UserParameter=agentd_conf.version,/usr/bin/md5sum /etc/zabbix/zabbix_agentd.conf | awk '{print $1}'  
UserParameter=getserver.info,/bin/sh /etc/zabbix/scripts/serverinfo
UserParameter=tcp.conn[*],/bin/sh /etc/zabbix/scripts/tcpconnection $1
UserParameter=asset.info[*],/bin/sh /etc/zabbix/scripts/assetinfo $1
UserParameter=ipvs.info[*],/bin/sh /etc/zabbix/scripts/ipvs $1
UserParameter=sys.load[*],/bin/sh /etc/zabbix/scripts/loadaverage.sh $1
UserParameter=disk.used,/bin/df | sed 1d | awk '{print $(NF-1)}' | awk -F% '{print $1}' | sort -n | tail -n 1

### Returning to CentOS 

Installing:
 zabbix-agent                                x86_64                                1.8.22-1.el6                                epel                                131 k
Installing for dependencies:
 zabbix                                      x86_64                                1.8.22-1.el6                                epel                                 93 k

##
$ rpm -ql zabbix-agent
/etc/init.d/zabbix-agent
/etc/logrotate.d/zabbix-agent
/etc/zabbix/zabbix_agent.conf
/etc/zabbix/zabbix_agentd.conf
/etc/zabbix/zabbix_snmptrap.conf
/usr/bin/zabbix_sender
/usr/bin/zabbix_snmptrap
/usr/sbin/zabbix_agent
/usr/sbin/zabbix_agentd
/usr/share/doc/zabbix-agent-1.8.22
/usr/share/doc/zabbix-agent-1.8.22/zabbix_snmptrap.README
/usr/share/man/man1/zabbix_sender.1.gz
/usr/share/man/man8/zabbix_agentd.8.gz

## Change client 's config ; 
# more /etc/zabbix/zabbix_agentd.conf |grep -v "#" |sed -e "/^$/d"
PidFile=/var/run/zabbix/zabbix_agentd.pid
LogFile=/var/log/zabbix/zabbix_agentd.log
LogFileSize=0
Server=172.22.40.250

# /etc/init.d/zabbix-agent start
Starting Zabbix agent:                                     [  OK  ]

## Back to the zabbix server ## means it's succeed ;
# /usr/bin/zabbix_get -s 10.66.66.23 -p10050 -k"net.if.in[eth0,bytes]"
3158748324131

## 我们的host 是通过web 点击？  via CLI ？ 
## 下面的服务器 什么都有了，进程 正常 ，配置正常；可是zabbix server还是无法 进行 监视；
root@AZ-Splunk:~# dpkg -L zamplus-zabbix-agent  

## OP03 上有监控项目 ！ 查查OP03 的 模板；
Host name：TS-OP03_172.22.40.251
In group:  Zamplus_Templates ;                     ## check group ? just a host group with 19 hosts ! with same usage; we have a Azure_host 
IP :172.22.40.251  ;  Port:10050 
By Proxy : no 
Status : Monitored 
---------------Templates                           ## check those templates ; 
Templates :
	3.0_core_create_time  -- 2 Items ;2 Triggers ;   ## 不理解呢；
		--core_create_time [disable]  
		--core_file_create
	3.0_MZ_Template_Ubuntu -- 12 application ；34 items ；Triggers ；Graphs 
	3.0_Port_80
---------------IPMI ? --Default-- Users 
---------------Macro [] - Value []
---------------History []


### An exsit host group for azure ; 
Azure_Host	Templates (0)
Hosts (10)	AZ-trk01_10.66.66.90, AZ-trk02_10.66.66.91, AZ-NGX01_10.66.66.86, AZ-NGX02_10.66.66.87, AZ-CM01_10.66.66.88, AZ-CM02_10.66.66.89, AZ-NGX03_10.66.66.92, AZ-NGX04_10.66.66.93, Azure-DaNgx01_10.66.66.27, Azure-DaNgx02_10.66.66.28

当默认监控无法满足 实际 要求 ； 我们借助 shell / python 脚本；
[root@monitor scripts]# catcheckservices.sh

2、在Zabbix_agentd.conf里面添加UserParameter，格式如下，对于Zabbix来说，脚本其实就是一个插件。
	1. UserParameter=checkservices.sh[*],/etc/zabbix/scripts/checkservices.sh $1 $2 

zabbix_get -s 10.66.66.23 -k checkservice.sh[EST_80]   ## 参数 是这么用的 ；

### 要 监控 的服务器 有多台 的时候，最简单的 方法 就是 先编写 一个【模板】templates； 在Link到要监控 的服务器上； 
### 给 【模板】 添加  【Items】（监控项）	
		--Name： HTTP_EST_NUM
		--Type： Zabbix_agent 
		--Key: 关键： checkservers.sh[EST_80]
### 为 【模板】 添加 【触发器】
		--Name： 			{HOST.NAME} HTTP 连接数 大于 20 
		--Expression: {Linux_service_templates:checkservices.sh[EST_80].prev(0)}>2000
		--Multiple {}
		--Description:{HOST.NAME}HTTP 连接数大于 2000 
		--URL {}
		--Severity ：High
		--Enabled {对号}

### 配置 【Graph】；实时查看http的链接情况；  一个【Graph】里面 可以添加 多个Item数据；
		-- 在http_connect_number （以后的吗?）里面 add
### 要查看 【Graphs】 在要 监控 的主机 上Link 刚才的模板 Linux_service_templates ; 
		-- 点击 template 然后add 吗？ 

### 回到我们的环境： 
### 【application】 -- 对应 【多个items】 【Triggers】

【template】 【application】 【Items】 【Triggers】 【Graphs】 【Screens】 【Discovery】 【Linked to】-（hosts）

###我要加的话：
-- host group ？ 
-- add template ，
-- 堆application ；
-- 堆item  ； 
-- 堆Trigger？ 
-- 

## 直接堆进 已有的template 的话？ 
-- 屡屡 以后的template 服务吗？ 


### WOW ；这个怎么办呢？  步骤有点乱 ；
--- 如果我先装 zabbix-agent ； 后期修改怎么办？
--- 我修改好了，重编rpm包？ --- 800 年后吧；
--- 发现ansible 工具，想花时间研究研究呢； 

{HADOOP-10.X-Ubuntu:agent.ping.nodata({$TRG_AGENT_PING_TIMEOUT})}=1


BH-172.22.5.127
In groups :
	hadoopNEW 
		TS-DN-050_172.22.5.50,  ## 服务器命名 很规范 呢； 但是貌似hostGroup没什么用呢； 
	HADOOP-10.X
		

In templates :                      ### 一个Datanode 继承了 3 个；
	HADOOP_port_1006
	HADOOP_port_proc_8042
	HADOOP_Template_Ubuntu


Template: HADOOP_Template_Ubuntu

HADOOP_Template_NeonCluster

Key：MEMused_percent
Formula： 100*last("memory_used")/last("vm.memory.size[total]")

### memory_used 
Key:memory_used    [select]
Formula : last("vm.memory.size[total]")-last("vm.memory.size[free]")-last("vm.memory.size[buffers]")-last("vm.memory.size[cached]")-last("vm.memory.size[shared]")





体检报销的问题； 


1 确保配置文件 全部更改；
ssh 10.66.66.32 'echo -e "master: 172.22.40.251\nid: `hostname`" > /etc/salt/minion'

2 确保salt-minion全部启动；

4 确保key全部添加 

5 验证非常慢啊，耐心；   循环竟然还丢了 ；

!id vince &&
倒叙；
do !ssh $i "id vince";salt add account ；


## well 其实这些 ，账户还是一定要加的；账户不通- salt就没有配好。 

10.66.66.36 salt 问题解决 ，root无密码登录还是不行；  用ansible来测试 ；

---
有了账户；  
1. 批量 装zabbix包；  zabbix-agent
2. ansible 批量 建立目录；
		/etc/zabbix/zabbix_agentd.conf
			Hostname=TS-HELIUM-001
			Server=172.22.25.7,172.22.40.250
			Include=/etc/zabbix/zabbix_agentd.conf.d/
3；ansible  copy文件模板；

4；zabbix 端 添加基本监控； zabbix测试命令；



## 包需要更新；
#ansible all -m yum -a "name=lzrz state=latest" -u root 


## 配置得更改；把脚本copy到所有服务器吗？ 
$ dpkg -L zamplus-zabbix-agent |grep etc 
$ more /etc/zabbix/zabbix_agentd.conf


## 是否可以在白云山上建一个proxy ； 也可以这次加过后 ，在加入配置里面；

## 目录得建立；
/etc/zabbix/zabbix_agentd.conf.d/ 

## 是否可兼容? 
$ ls /etc/zabbix/zabbix_agentd.conf.d/
core_file_created.conf  data_update_stat.conf  iostat.conf  os.basic.conf

## zabbix服务得启动； 

### 以上全是没有编译 RPM 的弊端； 一步步来； 
### 目标： 编译一个rpm解决上面所有问题； 建包，启动服务即可； 然后在web端添加； 



PidFile=/var/run/zabbix/zabbix_agentd.pid
LogFile=/var/log/zabbix-agent/zabbix_agentd.log
LogFileSize=0
DebugLevel=1
DisableActive=1
StartAgents=5
Timeout=30
Hostname=`hostname`
Server=172.22.40.250
Include=/etc/zabbix/zabbix_agentd.conf.d/


更简单方法；用已定义的模块来做 ；
$ ansible all -m authorized_key -a "user=mike key='{{ lookup('file', '/home/mike/.ssh/id_rsa.pub') }}' path=/home/mike/.ssh/authorized_keys manage_dir=no" --ask-pass -c paramiko

销毁脚本
ansible all -m file -a "dest=/tmp/id_rsa.pub state=absent" -u root ;

## 万一copy过去的脚本有错， 得不偿失； 还是全在一起编译一个rpm后再 传给所有 ； 挑战 ；
---------------

    
##########



# nc -n -v 172.22.25.7 10051
nc: connect to 172.22.25.7 port 10051 (tcp) failed: Connection timed out

加管理员组 ； 
再加 hadoop 的proxy 

最后再加host ； 

ln -s /usr/local/fe/files/template_preview /usr/local/fe/files/template_file/template_preview

 
netstat -an |awk '{print $4}' |grep 19800 

$ cat mega_baidu 
172.22.56.21
172.22.57.26
172.22.57.27
172.22.57.28
172.22.57.73
172.22.48.11
172.22.57.74
172.22.57.75

$ more mega_tanx 
172.22.56.1
172.22.57.22
172.22.57.23
172.22.57.40

172.22.57.48
172.22.48.9
172.22.57.55

172.22.57.71
172.22.57.62
172.22.57.61


vince@TS-OP03:~/tmp$ cat mega_sina 
172.22.57.24
172.22.57.25
172.22.57.58
172.22.57.71


Zabbix server IP: 192.168.101.11
Zabbix proxy server: 192.168.102.109
Zabbix agent: 172.1.16.2 (outside network but pingable from 102.109)



10.66.66.22 | success | rc=0 >>
12444

10.66.66.21 | success | rc=0 >>
14956

监控赶紧加上；


   43  more  /proc/sys/net/ipv4/tcp_max_tw_buckets
   44  echo 10000 > /proc/sys/net/ipv4/tcp_max_tw_buckets
   45  sysctl -p |grep tcp_max_tw_buckets
   
   
   60  echo 20000 > /proc/sys/net/ipv4/tcp_max_tw_buckets
   
sysctl set OK!!
useradd: user 'amos' already exists
we expect java version is 1.7.0_79,but currently java version is 
rpm: no packages given for erase
tar: /root/init_centos/jdk-7u79-linux-x64.gz: Cannot open: No such file or directory
tar: Error is not recoverable: exiting now
chown: cannot access `/opt/amos/jdk1.7.0_79': No such file or directory
init_centos.sh: line 154: [: =: unary operator expected


we expect java version is 1.7.0_79,but currently java version is 1.7.0_91
tar: /root/init_centos/jdk-7u79-linux-x64.gz: Cannot open: No such file or directory
tar: Error is not recoverable: exiting now
chown: cannot access `/opt/amos/jdk1.7.0_79': No such file or directory
init_centos.sh: line 154: [: =: unary operator expected




/home/azureuser/init_centos


echo "nameserver 114.114.114.114" >> /etc/resolv.conf

rpm -ivh epel-release-6-8.noarch.rpm rpmforge-release-0.5.2-2.el6.rf.x86_64.rpm


yum -y install salt-minion.noarch

cat > /etc/salt/minion1 << EEOF
master: 172.22.40.251
id: $(hostname)
EEOF



1. 我们来先讲Redhat的yum 这种高级的包管理.yum install gcc  [centos]更新：yum update
安装：yum install xxx
移除：yum remove xxx
清除已经安装过的档案（/var/cache/yum/）：yum clean all
搜寻：yum search xxx
列出所有档案：yum list
查询档案讯息：yum info xxx #sudo -s
#LANG=C
#yum -y install gcc gcc-c autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libpng libpng-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel用YUM安装软件包
yum -y <package_name>
命令：yum install <package_name>用YUM删除软件包
命令：yum remove <package_name> yum -y remove httpd* 
命令：yum search <keyword>列出所有可安装的软件包
命令：yum list yum list php*列出所有可更新的软件包
命令：yum list updates列出所有已安装的软件包
命令：yum list installed列出所有已安装但不在 Yum Repository 鹊娜砑包
命令：yum list extras列出所指定的软件包
命令：yum list <package_name> yum = Yellow dog Updater, Modified
主要功能是更方便的添加/删除/更新RPM包.它能便于管理大量系统的更新问题yum特点
可以同时配置多个资源库(Repository)
简洁的配置文件(/etc/yum.conf
自动解决增加或删除rpm包时遇到的倚赖性问题 保持与RPM数据库的一致性yum安装
CentOS 自带(yum-*.noarch.rpm)
#rpm -ivh yum-*.noarch.rpm
在第一次启用yum之前首先需要导入系统的RPM-GPG-KEY：
#rpm --import /usr/share/doc/centos-release-3(4)/RPM-GPG-KEY-CentOS-3(4) yum指令
注:当第一次使用yum或yum资源库有更新时,yum会自动下载 所有所需的headers放置于/var/cache/yum目录下,所需时间可能较长.rpm包的更新
检查可更新的rpm包
#yum check-update
更新所有的rpm包
#yum update
更新指定的rpm包,如更新kernel和kernel source
#yum update kernel kernel-source
大规模的版本升级,与yum update不同的是,连旧的淘汰的包也升级
#yum upgrade rpm包的安装和删除
安装rpm包,如xmms-mp3
#yum install xmms-mp3
删除rpm包,包括与该包有倚赖性的包
#yum remove licq
注:同时会提示删除licq-gnome,licq-qt,licq-text yum暂存(/var/cache/yum/)的相关参数
清除暂存中rpm包文件
#yum clean packages
清除暂存中rpm头文件
#yum clearn headers
清除暂存中旧的rpm头文件
#yum clean oldheaders
清除暂存中旧的rpm头文件和包文件
#yum clearn 或#yum clearn all
注:相当于yum clean packages + yum clean oldheaders包列表
列出资源库中所有可以安装或更新的rpm包
#yum list
列出资源库中特定的可以安装或更新以及已经安装的rpm包
#yum list mozilla#yum list mozilla*
注:可以在rpm包名中使用匹配符,如列出所有以mozilla开头的rpm包
列出资源库中所有可以更新的rpm包
#yum list updates
列出已经安装的所有的rpm包
#yum list installed
列出已经安装的但是不包含在资源库中的rpm包
#yum list extras
注:通过其它网站下载安装的rpm包rpm包信息显示(info参数同list)
列出资源库中所有可以安装或更新的rpm包的信息
#yum info
列出资源库中特定的可以安装或更新以及已经安装的rpm包的信息
#yum info mozilla#yum info mozilla*
注:可以在rpm包名中使用匹配符,如列出所有以mozilla开头的rpm包的信息
列出资源库中所有可以更新的rpm包的信息
#yum info updates
列出已经安装的所有的rpm包的信息
#yum info installed
列出已经安装的但是不包含在资源库中的rpm包的信息
#yum info extras
注:通过其它网站下载安装的rpm包的信息 搜索rpm包
搜索匹配特定字符的rpm包
#yum search mozilla
注:在rpm包名,包描述等中搜索
搜索有包含特定文件名的rpm包
#yum provides realplay增加资源库
例如:增加rpm.livna.org作为资源库
安装Livna.org rpms GPG key
#rpm --import http://rpm.livna.org/RPM-LIVNA-GPG-KEY
检查GPG Key
# rpm -qa gpg-pubkey*
显示Key信息
#rpm -qi gpg-pubkey-a109b1ec-3f6e28d5
(注:如果要删除Key,使用#rpm -e gpg-pubkey-a109b1ec-3f6e28d5) yum常用的命令# yum install xxx           安装xxx软件# yum info xxx               查看xxx软件的信息# yum remove xxx       删除软件包# yum list                       列出软件包# yum clean                   清除缓冲和就的包# yum provides xxx       以xxx为关键字搜索包（提供的信息为关键字）# yum search xxx          搜索软件包（以名字为关键字）# yum groupupdate xxx # yum grouplist xxx # yum groupremove xxx这三个都是一组为单位进行升级 列表和删除的操作。。比如 "Mysql Database"就是一个组会同时操作相关的所有软件包；# yum update               系统升级# yum list available       列出所有升级源上的包；# yum list updates        列出所有升级源上的可以更新包；# yum list installed        列出已经安装的包；# yun update kernel      升级内核；yum常用的源1) 自动选择最快的源 由于yum中有的mirror速度是非常慢的，如果yum选择了这个mirror，这个时候yum就会非常慢，对此，可以下载fastestmirror 插件，它会自动选择最快的mirror：#yum install yum-fastestmirror配置文件：（一般不用动）/etc/yum/pluginconf.d/fastestmirror.conf你的 yum镜像的速度测试记录文件：/var/cache/yum/timedhosts.txt (2)使用图形界面的yum如果觉得命令行的yum不方便，那么可以使用图形化的yumex，这个看起来更方便，因为可以自由地选择软件仓库：#yum install yumex然后在系统工具中就可以看到yum extender了。实际上系统自带的“添加/删除程序“也可以实现图形化的软件安装，但有些yumex的功能它没有。




2.讲讲Ubuntu中的高级包管 理方法apt-get
配置文件/etc/apt/sources.list
对于Server版， 推荐使用aptitude来查看，安装、删除deb包
sudo apt-get install aptitude
然后执行 sudo aptitude 进入管 理 也可以使用命令：
aptitude update 更新可用的包列表
aptitude upgrade 升级可用的包
aptitude dist-upgrade 将系统升级到新的发行版
aptitude install pkgname 安装包
aptitude remove pkgname 删除包
aptitude purge pkgname 删除包及其配置文件
aptitude search string 搜索包
aptitude show pkgname 显示包的详细信息
aptitude clean 删除下载的包文件
aptitude autoclean 仅删除过期的包文件 考虑到系统的兼容性,并且上面的东东比较都大,不找最新版本了，直接用apt-get install XXX来安装.因为我们的Ubuntu是dailyBulid的,所以光盘的内容基本上都是最新的了,无需重新下载.一定要最新版本的话，不妨先apt- get update 来更新一下软件的仓库,然后再 apt-get install.
常用的APT命令参数：apt-cache search package 搜索包apt-cache show package 获取包的相关信息，如说明、大小、版本等sudo apt-get install package 安装包sudo apt-get install package - - reinstall 重新安装包sudo apt-get -f install 修复安装"-f = ――fix-missing" sudo apt-get remove package 删除包sudo apt-get remove package - - purge 删除包，包括删除配置文件等sudo apt-get update 更新源sudo apt-get upgrade 更新已安装的包sudo apt-get dist-upgrade 升级系统sudo apt-get dselect-upgrade 使用 dselect 升级apt-cache depends package 了解使用依赖apt-cache rdepends package 是查看该包被哪些包依赖sudo apt-get build-dep package 安装相关的编译环境apt-get source package 下载该包的源代码sudo apt-get clean && sudo apt-get autoclean 清理无用的包sudo apt-get check 检查是否有损坏的依赖 

--dpkg【ubuntu】dpkg -l | grep 'php'  使用dpkg -l 来查看已经安装了的软件dpkg 是Debian[待宾] Package 的简写。为 Debian专门开发的套件管理系统，方便软件的安装、更新及移除。所有源自Debian的Linux 发行版都使用 dpkg，例如Ubuntu、Knoppix 等。
　　以下是一些 Dpkg 的普通用法：
　　1、dpkg -i <package.deb>
　　安装一个 Debian 软件包，如你手动下载的文件。
　　2、dpkg -c <package.deb>
　　列出 <package.deb> 的内容。
　　3、dpkg -I <package.deb>
　　从 <package.deb> 中提取包裹信息。
　　4、dpkg -r <package>　　5、dpkg -P <package>
　　完全清除一个已安装的包裹。和 remove 不同的是，remove 只是删掉数据和可执行文件，purge另外还删除所有的配制文件。
　　6、dpkg -L <package>
　　列出 <package> 安装的所有文件清单。同时请看 dpkg -c来检查一个 .deb 文件的内容。
　　7、dpkg -s <package>
　　显示已安装包裹的信息。同时请看 apt-cache 显示 Debian 存档中的包裹信息，以及 dpkg -I 来显示从一个.deb 文件中提取的包裹信息。
　　8、dpkg-reconfigure <package>
　　重新配制一个已经安装的包裹，如果它使用的是 debconf (debconf 为包裹安装提供了一个统一的配制界面)。


vince@TS-OP03:~/tmp$ cat mega_gdt 
ssh 172.22.56.1
ssh 172.22.57.22
ssh 172.22.57.23
ssh 172.22.57.40

ssh 172.22.57.48
ssh 172.22.48.9
ssh 172.22.57.55
ssh 172.22.57.62
ssh 172.22.57.61

vince@TS-OP03:~/tmp$ cat mega_baidu 
ssh 172.22.56.21
ssh 172.22.57.26
ssh 172.22.57.27
ssh 172.22.57.28

ssh 172.22.57.73
ssh 172.22.48.11
ssh 172.22.57.74
ssh 172.22.57.75

apt-get update
apt-get install zamplus-megatron-server

$ cat mega_baidu 
172.22.56.21
172.22.57.26
172.22.57.27
172.22.57.28
172.22.57.73
172.22.48.11
172.22.57.74
172.22.57.75

$ more mega_tanx 
172.22.56.1
172.22.57.22
172.22.57.23
172.22.57.40

172.22.57.48
172.22.48.9
172.22.57.55

172.22.57.71
172.22.57.62
172.22.57.61

cat mega_sina 
172.22.57.24
172.22.57.25
172.22.57.58
172.22.57.71


sshpass-1.05-1.el6.rf.x86_64


403889328	/var/log/billing/log


     
# cat admin                  
local_root=/home/ftp                  
anon_world_readable_only=NO              
write_enable=YES             
anon_mkdir_write_enable=YES  
anon_upload_enable=YES               
anon_other_write_enable=YES  


# cat download              
local_root=/home/ftp        
anon_world_readable_only=NO 


# cat web                  
local_root=/var/www        
anon_world_readable_only=NO
anon_umask=022             
write_enable=YES           
anon_mkdir_write_enable=YES
anon_upload_enable=YES     
anon_other_write_enable=YES





##########
mysql> use vsftpdvu;
Database changed
mysql> 
mysql> 
mysql> create table users(name char(16) binary,passwd char(16) binary);
Query OK, 0 rows affected (0.02 sec)

mysql> insert into users (name,passwd) values ("download",password("download"));
Query OK, 1 row affected, 1 warning (0.00 sec)

mysql> insert into users (name,passwd) values ("admin",password("admin"));
Query OK, 1 row affected, 1 warning (0.00 sec)

mysql> insert into users (name,passwd) values ("web",password("web"));
Query OK, 1 row affected, 1 warning (0.00 sec)

mysql> grant select on vsftpdvu.users to virtual@localhost identified by "123456";
Query OK, 0 rows affected (0.00 sec)

mysql> quit

# mysql -u virtual -p123456 vsftpdvu

mysql> select * from users;
+----------+------------------+
| name     | passwd           |
+----------+------------------+
| download | *E35CB5A3C760245 |
| admin    | *4ACFE3202A5FF5C |
| web      | *7F3BF7031A324F9 |
+----------+------------------+
3 rows in set (0.00 sec)

mysql> 

Install a new environment ？ where is mysql ；where is vsftpd ？ 

deb http://mirrors.ustc.edu.cn/ubuntu/ precise-updates main restricted
deb-src http://mirrors.ustc.edu.cn/ubuntu/ precise-updates main restricted
deb http://mirrors.ustc.edu.cn/ubuntu/ precise universe
deb-src http://mirrors.ustc.edu.cn/ubuntu/ precise universe
deb http://mirrors.ustc.edu.cn/ubuntu/ precise-updates universe
deb-src http://mirrors.ustc.edu.cn/ubuntu/ precise-updates universe
deb http://mirrors.ustc.edu.cn/ubuntu/ precise multiverse
deb-src http://mirrors.ustc.edu.cn/ubuntu/ precise multiverse
deb http://mirrors.ustc.edu.cn/ubuntu/ precise-updates multiverse
deb-src http://mirrors.ustc.edu.cn/ubuntu/ precise-updates multiverse
deb http://mirrors.ustc.edu.cn/ubuntu/ precise-backports main restricted universe multiverse
deb-src http://mirrors.ustc.edu.cn/ubuntu/ precise-backports main restricted universe multiverse
deb http://security.ubuntu.com/ubuntu precise-security main restricted
deb-src http://security.ubuntu.com/ubuntu precise-security main restricted
deb http://security.ubuntu.com/ubuntu precise-security universe
deb-src http://security.ubuntu.com/ubuntu precise-security universe
deb http://security.ubuntu.com/ubuntu precise-security multiverse
deb-src http://security.ubuntu.com/ubuntu precise-security multiverse

deb http://mirrors.sohu.com/ubuntu/ precise-updates main restricted
deb-src http://mirrors.sohu.com/ubuntu/ precise-updates main restricted
deb http://mirrors.sohu.com/ubuntu/ precise universe
deb-src http://mirrors.sohu.com/ubuntu/ precise universe
deb http://mirrors.sohu.com/ubuntu/ precise-updates universe
deb-src http://mirrors.sohu.com/ubuntu/ precise-updates universe
deb http://mirrors.sohu.com/ubuntu/ precise multiverse
deb-src http://mirrors.sohu.com/ubuntu/ precise multiverse
deb http://mirrors.sohu.com/ubuntu/ precise-updates multiverse
deb-src http://mirrors.sohu.com/ubuntu/ precise-updates multiverse
deb http://mirrors.sohu.com/ubuntu/ precise-backports main restricted universe multiverse
deb-src http://mirrors.sohu.com/ubuntu/ precise-backports main restricted universe multiverse


42.159.247.176



